---
layout: post

title: Use SMOTE to deal with imbalanced datasets

tip-number: 30
tip-username: dzlab
tip-username-profile: https://github.com/dzlab
tip-tldr: Learn a how to work with imbalanced datasets and improve performance on minority class with SMOTE
tip-writer-support: https://www.patreon.com/dzlab

categories:
    - en
    - more
---

An imbalanced datasets is hard to deal with for most ML algorithms, as the model have hard time learning the decision boundaries between the classes.

<div id="histogram1"></div>
<script>
var x = ["0","0","0","0","0","1","0","0","0","0"]
var data = [
  {
    histfunc: "count",
    x: x,
    type: "histogram",
    name: "count"
  }
]
var layout = {
  title:'Examples per class'
}
Plotly.newPlot('histogram1', data, layout);
</script>

One way to address this problem is by oversampling examples from the minority class, for instance by simply duplicating examples from the minority class. Such approach does not provide any additional information to the model, so a better approach would be to generate synthetic examples.

[SMOTE](https://arxiv.org/abs/1106.1813) which stands for Synthetic Minority Oversampling Technique is a widely used approach for generating synthetic examples for the minority class. It works by:
- selecting a random example from the minority class
- finding the k (typically k=5) nearest neighbors of that example
- selecting a random example from those neighbors
- drawing a line between those two examples
- generating a synthetic example by choosing a random point from that line

An implementations of SMOTE is provided in the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) Python library which can be install with `pip` as follows:

```sh
$ pip install imbalanced-learn
```

The following is an example of using the [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html) technique to balance a classification dataset:
```python
from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE

# Generate some data for a classification problem
X, y = make_classification(
    n_classes=2,
    class_sep=2,
    weights=[0.1, 0.9],
    n_informative=3,
    n_redundant=1,
    flip_y=0,
    n_features=20,
    n_clusters_per_class=1,
    n_samples=1000,
    random_state=42
)

# Count of samples per class -> {1: 900, 0: 100}
print('Original dataset shape %s' % Counter(y))

# Apply SMOTE to balance the dataset
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)

# New count after balancing -> {0: 900, 1: 900}
print('Resampled dataset shape %s' % Counter(y_res))
```
